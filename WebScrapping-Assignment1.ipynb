{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4509c2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "url = \"https://en.wikipedia.org/wiki/Main_Page\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "header_tags = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])\n",
    "headers = [tag.text.strip() for tag in header_tags]\n",
    "headers_df = pd.DataFrame({'Headers': headers})\n",
    "print(\"Header Tags:\")\n",
    "print(headers_df)\n",
    "--------------------------------------------------------------------------------------------------------------------------------\n",
    "3 a. \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "team_rankings_url = \"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\"\n",
    "response = requests.get(team_rankings_url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "table = soup.find('table', class_='table')\n",
    "teams = []\n",
    "matches = []\n",
    "points = []\n",
    "ratings = []\n",
    "for row in table.find_all('tr')[1:11]:  # Skip the header row and limit to top 10 teams\n",
    "    cols = row.find_all('td')\n",
    "    teams.append(cols[1].text.strip())\n",
    "    matches.append(cols[2].text.strip())\n",
    "    points.append(cols[3].text.strip())\n",
    "    ratings.append(cols[4].text.strip())\n",
    "teams_df = pd.DataFrame({\n",
    "    'Team': teams,\n",
    "    'Matches': matches,\n",
    "    'Points': points,\n",
    "    'Rating': ratings\n",
    "})\n",
    "print(\"Top 10 ODI Teams in Men's Cricket:\")\n",
    "print(teams_df)\n",
    "--------------------------------------------------------------------------------------------------------------------------------\n",
    "3b. \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "batsmen_rankings_url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\"\n",
    "response = requests.get(batsmen_rankings_url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "batsmen = []\n",
    "teams = []\n",
    "ratings = []\n",
    "for row in soup.select('table.table tr.table-body')[0:10]:  \n",
    "    cols = row.find_all('td')\n",
    "    batsmen.append(cols[1].text.strip())\n",
    "    teams.append(cols[2].text.strip())\n",
    "    ratings.append(cols[3].text.strip())\n",
    "batsmen_df = pd.DataFrame({\n",
    "    'Batsman': batsmen,\n",
    "    'Team': teams,\n",
    "    'Rating': ratings\n",
    "})\n",
    "print(\"Top 10 ODI Batsmen:\")\n",
    "print(batsmen_df)\n",
    "--------------------------------------------------------------------------------------------------------------------------------\n",
    "3c. \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "bowlers_rankings_url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\"\n",
    "response = requests.get(bowlers_rankings_url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "bowlers = []\n",
    "teams = []\n",
    "ratings = []\n",
    "for row in soup.select('table.table tr.table-body')[0:10]:  # Limit to top 10 bowlers\n",
    "    cols = row.find_all('td')\n",
    "    bowlers.append(cols[1].text.strip())\n",
    "    teams.append(cols[2].text.strip())\n",
    "    ratings.append(cols[3].text.strip())\n",
    "bowlers_df = pd.DataFrame({\n",
    "    'Bowler': bowlers,\n",
    "    'Team': teams,\n",
    "    'Rating': ratings\n",
    "})\n",
    "print(\"Top 10 ODI Bowlers:\")\n",
    "print(bowlers_df)\n",
    "--------------------------------------------------------------------------------------------------------------------------------\n",
    "4 a \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "women_teams_rankings_url = \"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\"\n",
    "response = requests.get(women_teams_rankings_url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "table = soup.find('table', class_='table')\n",
    "teams = []\n",
    "matches = []\n",
    "points = []\n",
    "ratings = []\n",
    "for row in table.find_all('tr')[1:11]:  \n",
    "    cols = row.find_all('td')\n",
    "    teams.append(cols[1].text.strip())\n",
    "    matches.append(cols[2].text.strip())\n",
    "    points.append(cols[3].text.strip())\n",
    "    ratings.append(cols[4].text.strip())\n",
    "women_teams_df = pd.DataFrame({\n",
    "    'Team': teams,\n",
    "    'Matches': matches,\n",
    "    'Points': points,\n",
    "    'Rating': ratings\n",
    "})\n",
    "print(\"Top 10 ODI Women's Cricket Teams:\")\n",
    "print(women_teams_df)\n",
    "--------------------------------------------------------------------------------------------------------------------------------\n",
    "4 b \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "women_batting_rankings_url = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\"\n",
    "response = requests.get(women_batting_rankings_url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "batsmen = []\n",
    "teams = []\n",
    "ratings = []\n",
    "for row in soup.select('table.table tr.table-body')[0:10]:  \n",
    "    cols = row.find_all('td')\n",
    "    batsmen.append(cols[1].text.strip())\n",
    "    teams.append(cols[2].text.strip())\n",
    "    ratings.append(cols[3].text.strip())\n",
    "women_batting_df = pd.DataFrame({\n",
    "    'Batswoman': batsmen,\n",
    "    'Team': teams,\n",
    "    'Rating': ratings\n",
    "})\n",
    "print(\"Top 10 Women's ODI Batting Players:\")\n",
    "print(women_batting_df)\n",
    "--------------------------------------------------------------------------------------------------------------------------------\n",
    "4 c\n",
    " import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "women_all_rounder_rankings_url = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\"\n",
    "response = requests.get(women_all_rounder_rankings_url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "all_rounders = []\n",
    "teams = []\n",
    "ratings = []\n",
    "for row in soup.select('table.table tr.table-body')[0:10]:  \n",
    "    cols = row.find_all('td')\n",
    "    all_rounders.append(cols[1].text.strip())\n",
    "    teams.append(cols[2].text.strip())\n",
    "    ratings.append(cols[3].text.strip())\n",
    "women_all_rounder_df = pd.DataFrame({\n",
    "    'All-Rounder': all_rounders,\n",
    "    'Team': teams,\n",
    "    'Rating': ratings\n",
    "})\n",
    "print(\"Top 10 Women's ODI All-Rounders:\")\n",
    "print(women_all_rounder_df)\n",
    "--------------------------------------------------------------------------------------------------------------------------------\n",
    "5 \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd \n",
    "response = requests.get(\"https://www.cnbc.com/world/?region=world\")\n",
    "soup = BeautifulSoup(response.content)\n",
    "Headline = []\n",
    "for head in soup.find_all('a',class_=\"LatestNews-headline\"):\n",
    "    Headline.append(head.text)\n",
    "Headline\n",
    "Time = []\n",
    "for time in soup.find_all('span', class_=\"LatestNews-wrapper\"):\n",
    "    Time.append(time.text)\n",
    "Time\n",
    "df = pd.DataFrame({'Headline':Headline,'Time':Time})\n",
    "df\n",
    "--------------------------------------------------------------------------------------------------------------------------------\n",
    "6. \n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "page = requests.get(\"https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\")\n",
    "soup = BeautifulSoup(page.content)\n",
    "first_title = soup.find('h2',class_=\"sc-1qrq3sd-1 gRGSUS sc-1nmom32-0 sc-1nmom32-1 btcbYu goSKRg\")\n",
    "first_title.text\n",
    "author = soup.find('span',class_=\"sc-1w3fpd7-0 dnCnAO\")\n",
    "author.text\n",
    "datepub = soup.find('span',class_=\"sc-1thf9ly-2 dvggWt\")\n",
    "datepub.text\n",
    "all_titles=[]\n",
    "for i in soup.find_all('h2',class_=\"sc-1qrq3sd-1 gRGSUS sc-1nmom32-0 sc-1nmom32-1 btcbYu goSKRg\"):\n",
    "    all_titles.append(i.text)\n",
    "all_author=[]\n",
    "for j in soup.find_all('span',class_=\"sc-1w3fpd7-0 dnCnAO\"):\n",
    "    all_author.append(j.text)\n",
    "all_datepubs=[]\n",
    "for l in soup.find_all('span',class_=\"sc-1thf9ly-2 dvggWt\"):\n",
    "    all_datepubs.append(l.text)\n",
    "df = pd.DataFrame({'Article Name':all_titles,'Author Name':all_author,'Publication Date':all_datepubs})\n",
    "df\n",
    "--------------------------------------------------------------------------------------------------------------------------------\n",
    "7.\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "page = requests.get(\"https://www.dineout.co.in/delhi-restaurants/buffet-special\")\n",
    "soup = BeautifulSoup(page.content)\n",
    "RestaurantName = []\n",
    "for r in soup.find_all('div',class_=\"restnt-info cursor\"):\n",
    "    RestaurantName.append(r.text)\n",
    "LocationName = []\n",
    "for loc in soup.find_all('div',class_=\"restnt-loc ellipsis\"):\n",
    "    LocationName.append(loc.text)\n",
    "Rating  = []\n",
    "for rat in soup.find_all('div',class_=\"restnt-rating rating-4\"):\n",
    "    Rating.append(rat.text)\n",
    "images = []\n",
    "for t in soup.find_all('img',class_=\"no-img\"):\n",
    "    images.append(t['data-src'])\n",
    "df = pd.DataFrame({'Restaurant Name':RestaurantName,'Location':LocationName,'Rating':Rating,'ImageURL':images})\n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
